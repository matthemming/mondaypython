{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from urllib import request\n",
    "from pprint import pprint\n",
    "from datetime import datetime as dt\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_url = 'http://www.cambsfire.gov.uk/news-and-incidents/incidents.aspx'\n",
    "req = request.Request(start_url, headers={'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.67 Safari/537.36'})\n",
    "content = request.urlopen(req)\n",
    "p1_soup = BeautifulSoup(content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listpage_scrape(list_page_url):\n",
    "    '''function takes the url of a page at \n",
    "    http://www.cambsfire.gov.uk/news-and-incidents/\n",
    "    and returns a list of dictionaries with \n",
    "    the incident title, date and text'''\n",
    "    ua_header = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.67 Safari/537.36'}\n",
    "    \n",
    "    req = request.Request(list_page_url, headers=ua_header)\n",
    "    content = request.urlopen(req)\n",
    "    list_page_soup = BeautifulSoup(content, 'html.parser').find('div', class_='main-content')\n",
    "\n",
    "    incids_list = []\n",
    "\n",
    "    try:\n",
    "        for event in list_page_soup.findAll('div', class_='row')[:-1]: # rows are events, last row is navigation pane\n",
    "            url = 'http://www.cambsfire.gov.uk' + event.find('a')['href']\n",
    "            req = request.Request(url, headers=ua_header)\n",
    "            content = request.urlopen(req)\n",
    "            soup = BeautifulSoup(content, 'html.parser')\n",
    "        \n",
    "            incid_dict = {}\n",
    "        \n",
    "            incid_dict['title'] = soup.find('h1', class_='content-title').text\n",
    "            incid_dict['date'] = soup.find('p', class_='content-date').text\n",
    "            incid_dict['text'] = ' '.join([p.text for p in soup.find('div', class_='main-content-body').findAll('p')]).replace(u'\\xa0', u' ')\n",
    "            \n",
    "            incids_list.append(incid_dict)\n",
    "            \n",
    "            #time.sleep(0.5)    \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return incids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_urls(url):\n",
    "    '''function takes the url of a page at \n",
    "    http://www.cambsfire.gov.uk/news-and-incidents/\n",
    "    and returns a list of the urls of the pages \n",
    "    linked to in the navigation bar at the bottom'''\n",
    "    \n",
    "    ua_header = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.67 Safari/537.36'}\n",
    "    \n",
    "    req = request.Request(url, headers=ua_header)\n",
    "    content = request.urlopen(req)\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    url_list = []\n",
    "    for page_url in soup.find('div', class_='cfrs-pagenumbers').findAll('a')[:-1]:\n",
    "        url_list.append('http://www.cambsfire.gov.uk' + page_url['href'])\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_archive_urls(url):\n",
    "    '''function takes the url of a page at \n",
    "    http://www.cambsfire.gov.uk/news-and-incidents/\n",
    "    and returns a list of the urls of the pages \n",
    "    linked to in the navigation bar at the bottom'''\n",
    "    ua_header = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.67 Safari/537.36'}\n",
    "    \n",
    "    req = request.Request(url, headers=ua_header)\n",
    "    content = request.urlopen(req)\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    archive_urls = soup.findAll('div', class_='cfrs-area-navigation')[1].findAll('a')\n",
    "    archive_urls = ['http://www.cambsfire.gov.uk' + a['href'] for a in archive_urls]\n",
    "    return archive_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the page with the most recent incident reports on\n",
    "start_page_url = 'http://www.cambsfire.gov.uk/news-and-incidents/incidents.aspx'\n",
    "\n",
    "ua_header = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.67 Safari/537.36'}\n",
    "    \n",
    "req = request.Request(testpageurl, headers=ua_header)\n",
    "content = request.urlopen(req)\n",
    "start_page_soup = BeautifulSoup(content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The archive urls are scraped from the initial incident report page\n",
    "archive_urls = start_page_soup.findAll('div', class_='cfrs-area-navigation')[1].findAll('a')\n",
    "archive_urls = ['http://www.cambsfire.gov.uk' + a['href'] for a in archive_urls]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_page_url = 'http://www.cambsfire.gov.uk/news-and-incidents/incidents.aspx'\n",
    "\n",
    "allrecords = []\n",
    "\n",
    "# this is a list of the root pages (the start page of most recent incidents and all of the archives)\n",
    "root_page_urls = [start_page_url] +  get_archive_urls(start_page_url)\n",
    "\n",
    "# this iterates through all of the root page urls, visiting each page listed in the navigation pane at the bottom\n",
    "# and scrapes information from each of the record links contained in these list pages\n",
    "for root_page in root_page_urls:\n",
    "    for records_page in get_page_urls(root_page):\n",
    "        allrecords = allrecords + listpage_scrape(records_page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(allrecords).to_csv(r'C:\\git\\fire\\data\\Fire_Regions\\CambridgeshireFire.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
